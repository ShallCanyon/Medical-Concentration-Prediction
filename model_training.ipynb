{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import os\n",
    "import deepchem as dc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, mean_squared_log_error, mean_absolute_error, r2_score\n",
    "import sklearn.metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brainblood_csv(workbookpath, csvfilepath):\n",
    "    excel_df = pd.read_excel(workbookpath, index_col=[0, 1], engine='openpyxl')\n",
    "    # column_list = excel_df.columns.to_list()\n",
    "    # print(column_list)\n",
    "    blood_df = excel_df.loc[:, excel_df.columns.str.startswith('blood mean')]\n",
    "    brain_df = excel_df.loc[:, excel_df.columns.str.startswith('brain mean')]\n",
    "    print(blood_df.columns.to_list())\n",
    "    print(brain_df.columns.to_list())\n",
    "    df = pd.concat([blood_df, brain_df], axis=1)\n",
    "    df.to_csv(csvfilepath, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_blood_brain_ratio(raw_csvfilepath, ratio_csvfilepath):\n",
    "    raw_df = pd.read_csv(raw_csvfilepath, index_col=[0, 1])\n",
    "    blood_df = raw_df.loc[:, raw_df.columns.str.startswith('blood mean')]\n",
    "    brain_df = raw_df.loc[:, raw_df.columns.str.startswith('brain mean')]\n",
    "    # 以{(化合物文献号，SMILE) -> {浓度数据}}的格式存储数据\n",
    "    compound_ratio = dict()\n",
    "    for index, blood_row_data in blood_df.iterrows():\n",
    "        # 血液行数据\n",
    "        blood_row_data = blood_row_data.dropna()\n",
    "        # 脑部行数据\n",
    "        brain_row_data = brain_df.loc[index[0]].dropna(axis=1, how='all')\n",
    "        # 任意一个器官内数据为空，跳过\n",
    "        if brain_row_data.empty or blood_row_data.empty:\n",
    "            continue\n",
    "        else:\n",
    "            # 以{(时间) -> (脑血浓度比)}的格式存储数据\n",
    "            ratio2time = dict()\n",
    "            # 转换series为dataframe\n",
    "            blood_row_data = blood_row_data.to_frame()\n",
    "            blood_row_data = pd.DataFrame(blood_row_data.values.T, columns=blood_row_data.index)\n",
    "\n",
    "            for column in blood_row_data.columns.to_list():\n",
    "                # 获取血液浓度\n",
    "                blood_num = float(blood_row_data[column].values[0])\n",
    "                # 拆分列头以获取时间点，组合成脑部浓度数据时间点\n",
    "                tgt_col = 'brain ' + column.split(\" \")[1]\n",
    "                # 判断该脑部数据时间点是否存在\n",
    "                if tgt_col in brain_row_data.columns.to_list():\n",
    "                    # 获取脑部浓度\n",
    "                    brain_num = float(brain_row_data[tgt_col].values[0])\n",
    "                    brainbloodratio = brain_num / blood_num\n",
    "                    # 按照脑部浓度、血液浓度和脑血浓度比3种数据以列表格式保存到字典中\n",
    "                    ratio2time[column.split(\" \")[1].replace('mean', '')] = [brain_num, blood_num, brainbloodratio]\n",
    "        # kv[1][2]指定为以脑血浓度比进行降序排序\n",
    "        sorted_data = sorted(ratio2time.items(), key=lambda kv: (kv[1][2], kv[0]), reverse=True)\n",
    "        # print(sorted_data)\n",
    "        # 获取最大脑血浓度比的数据\n",
    "        compound_ratio[index] = sorted_data[0]\n",
    "    # 将字典转换成Dataframe所需的列表格式\n",
    "    max_ratio_list = []\n",
    "    for key, value in compound_ratio.items():\n",
    "        index = key[0]\n",
    "        smiles = key[1]\n",
    "        time = value[0]\n",
    "        brain_num = value[1][0]\n",
    "        blood_num = value[1][1]\n",
    "        ratio = value[1][2]\n",
    "        max_ratio_list.append([index, smiles, brain_num, blood_num, ratio, time])\n",
    "    df = pd.DataFrame(data=max_ratio_list, columns=['Compound index', 'SMILES', 'Brain', 'Blood', 'Brain/Blood', 'Reach time'])\n",
    "\n",
    "    #     # 降序排序并获取第一个最大值\n",
    "    #     compound_ratio[index] = sorted(ratio2time.items(), key=lambda kv: (kv[1], kv[0]), reverse=True)[0]\n",
    "    # # 将字典转换成Dataframe所需的列表格式\n",
    "    # max_ratio_list = []\n",
    "    # for key, value in compound_ratio.items():\n",
    "    #     index = key[0]\n",
    "    #     smiles = key[1]\n",
    "    #     time = value[0]\n",
    "    #     ratio = value[1]\n",
    "    #     max_ratio_list.append([index, smiles, ratio, time])\n",
    "    # df = pd.DataFrame(data=max_ratio_list, columns=['Compound index', 'SMILES', 'Max(Brain/Blood)', 'Reach time'])\n",
    "    # print(df)\n",
    "    df.to_csv(ratio_csvfilepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_desc(srcfile, dstfile):\n",
    "    df = pd.read_csv(srcfile)\n",
    "    featurizer = dc.feat.MordredDescriptors(ignore_3D=True)\n",
    "    SMILES = df['SMILES']\n",
    "    X = []\n",
    "    for smiles in SMILES:\n",
    "        X.append(featurizer.featurize(smiles)[0])\n",
    "    blood = df['Blood']\n",
    "    brain = df['Brain']\n",
    "    ratio = df['Brain/Blood']\n",
    "    df = pd.DataFrame(data=X)\n",
    "    df.insert(0, 'SMILES', SMILES)\n",
    "    df.insert(1, 'Blood', blood)\n",
    "    df.insert(2, 'Brain', brain)\n",
    "    df.insert(3, 'Ratio', ratio)\n",
    "    df.to_csv(dstfile, index=False)\n",
    "\n",
    "def get_X_Y(csvfile):\n",
    "    df = pd.read_csv(csvfile)\n",
    "    X = df.drop(['SMILES', 'Blood', 'Brain', 'Ratio'], axis=1)\n",
    "    X = MinMaxScaler().fit_transform(X)\n",
    "    # print(len(X))\n",
    "    blood_y = df['Blood'].ravel()\n",
    "    brain_y = df['Brain'].ravel()\n",
    "    ratio_y = df['Ratio'].ravel()\n",
    "    SMILES = df['SMILES']\n",
    "    return pd.DataFrame(X), blood_y, brain_y, ratio_y, SMILES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "Start training model...\n"
     ]
    }
   ],
   "source": [
    "filetime = \"20221221\"\n",
    "# 原始的集成数据集\n",
    "workbookpath = f\"./result/{filetime}/数据表汇总.xlsx\"\n",
    "# 从原始数据集中挑选出脑部与血液浓度的数据集\n",
    "raw_csvfilepath = f\"./result/{filetime}/BrainBlood.csv\"\n",
    "# 计算得到最大脑血比的数据集\n",
    "ratio_csvfilepath = f\"./result/{filetime}/MaxBrainBloodRatio.csv\"\n",
    "# 计算出药物的Mordred描述符以及最大脑血比的数据集\n",
    "desc_csvfilepath = f\"./result/{filetime}/RatioDescriptors.csv\"\n",
    "generate_new_data = [False, False, False]\n",
    "regressor_type = 'LGBM'\n",
    "\n",
    "print(\"Running...\")\n",
    "if not os.path.exists(raw_csvfilepath) or generate_new_data[0]:\n",
    "    print(\"Getting blood brain file...\")\n",
    "    get_brainblood_csv(workbookpath, raw_csvfilepath)\n",
    "\n",
    "if not os.path.exists(ratio_csvfilepath) or generate_new_data[1]:\n",
    "    print(\"Calculating blood brain ratio...\")\n",
    "    calculate_blood_brain_ratio(raw_csvfilepath, ratio_csvfilepath)\n",
    "\n",
    "if not os.path.exists(desc_csvfilepath) or generate_new_data[2]:\n",
    "    print(\"Calculating descriptors...\")\n",
    "    calculate_desc(ratio_csvfilepath, desc_csvfilepath)\n",
    "\n",
    "X, blood_y, brain_y, ratio_y, SMILES = get_X_Y(desc_csvfilepath)\n",
    "feature_select = True\n",
    "if feature_select:\n",
    "    # 特征筛选\n",
    "    # blood_fea = [162, 222, 254, 255, 261, 300, 320, 325, 338, 369, 396, 441, 446, 474, 481, 489, 502, 514, 529, 530, 541, 549, 565, 568, 570, 582, 594, 598, 602, 631, 632, 638, 645, 646, 648, 802, 807, 832, 986, 1145, 1226, 1232, 1266, 1287, 1289, 1297, 1316, 1356, 1539, 1544]\n",
    "    blood_fea = [5, 10, 60, 76, 111, 129, 132, 142, 150, 151, 162, 164, 168, 183, 184, 186, 196, 203, 220, 222, 223, 230, 231, 243, 246, 247, 254, 255, 261, 264, 270, 289, 300, 310, 311, 320, 323, 325, 333, 334, 337, 338, 350, 359, 368, 369, 396, 397, 404, 405, 414, 422, 441, 446, 449, 452, 453, 458, 465, 466, 474, 481, 489, 497, 498, 502, 506, 513, 514, 522, 529, 530, 534, 540, 541, 542, 546, 549, 561, 565, 566, 567, 568, 570, 572, 581, 582, 589, 594, 597, 598, 599, 600, 602, 604, 610, 618, 626, 629, 630, 631, 632, 637, 638, 642, 644, 645, 646, 648, 665, 781, 788, 791, 802, 803, 807, 814, 816, 825, 832, 838, 846, 847, 848, 978, 981, 986, 987, 999, 1055, 1057, 1065, 1072, 1086, 1134, 1136, 1139, 1143, 1144, 1145, 1156, 1157, 1161, 1163, 1165, 1209, 1211, 1217, 1219, 1221, 1226, 1228, 1232, 1235, 1236, 1238, 1245, 1249, 1250, 1252, 1253, 1257, 1259, 1262, 1263, 1266, 1278, 1281, 1282, 1286, 1287, 1289, 1297, 1301, 1306, 1309, 1311, 1314, 1319, 1325, 1328, 1330, 1333, 1337, 1356, 1357, 1358, 1360, 1362, 1377, 1382, 1523, 1524, 1539, 1540, 1541, 1543, 1544, 1545, 1547]\n",
    "    # brain_fea = [3, 40, 150, 164, 243, 246, 254, 255, 261, 310, 342, 368, 369, 449, 450, 458, 497, 506, 529, 542, 549, 578, 602, 604, 610, 618, 637, 642, 644, 646, 770, 781, 801, 814, 846, 986, 999, 1065, 1078, 1136, 1143, 1157, 1278, 1316, 1329, 1330, 1336, 1543, 1545, 1547]\n",
    "    brain_fea = [3, 10, 36, 38, 39, 40, 57, 60, 69, 75, 76, 78, 83, 123, 136, 138, 141, 142, 143, 146, 150, 162, 163, 164, 168, 178, 186, 194, 195, 212, 213, 214, 222, 230, 232, 243, 246, 254, 255, 261, 264, 270, 289, 310, 319, 325, 333, 337, 338, 341, 342, 350, 368, 369, 396, 414, 423, 441, 446, 449, 450, 452, 457, 458, 465, 466, 474, 481, 497, 498, 506, 514, 522, 529, 530, 534, 541, 542, 546, 549, 561, 566, 567, 568, 570, 572, 574, 578, 581, 589, 597, 598, 602, 604, 610, 618, 626, 630, 631, 632, 637, 638, 642, 644, 645, 646, 648, 665, 770, 780, 781, 791, 801, 807, 812, 814, 815, 816, 825, 831, 835, 845, 846, 981, 986, 999, 1055, 1060, 1065, 1077, 1078, 1084, 1086, 1136, 1139, 1143, 1144, 1151, 1157, 1162, 1163, 1165, 1209, 1211, 1217, 1219, 1221, 1226, 1228, 1232, 1233, 1234, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1253, 1256, 1259, 1266, 1278, 1281, 1285, 1286, 1287, 1289, 1297, 1302, 1306, 1314, 1316, 1319, 1325, 1329, 1330, 1336, 1339, 1352, 1356, 1357, 1360, 1362, 1376, 1523, 1524, 1532, 1533, 1538, 1539, 1540, 1541, 1543, 1544, 1545, 1546, 1547, 1548]\n",
    "    blood_X = X.iloc[:, blood_fea]\n",
    "    brain_X = X.iloc[:, brain_fea]\n",
    "else:\n",
    "    blood_X = X\n",
    "    brain_X = X\n",
    "\n",
    "print(\"Start training model...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, model, cv_times=5, callback=None):\n",
    "    cv = KFold(n_splits=cv_times, shuffle=True)\n",
    "\n",
    "    r2_scores = np.empty(cv_times)\n",
    "    rmse_scores = np.empty(cv_times)\n",
    "    \n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        model.fit(X_train, y_train, eval_set=[\n",
    "            (X_test, y_test)], callbacks=callback) # early_stopping_rounds=100, verbose=False,\n",
    "        preds = model.predict(X_test)\n",
    "\n",
    "        r2 = r2_score(y_test, preds)\n",
    "        r2_scores[idx] = r2\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "        rmse_scores[idx] = rmse\n",
    "    # print(cv_scores)\n",
    "    # print(\"R2 Scores: %0.4f (+/- %0.2f)\" %\n",
    "    #     (r2_scores.mean(), r2_scores.std()))\n",
    "    # print(\"RMSE Scores: %0.4f (+/- %0.2f)\" %\n",
    "    #     (rmse_scores.mean(), rmse_scores.std()))\n",
    "    # score = cross_val_score(clf, X, y, cv=cv_times, scoring='r2')\n",
    "    return r2_scores, rmse_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood data:\n",
      "R2 Scores: 0.4404 (+/- 0.15)\n",
      "RMSE Scores: 4.6320 (+/- 1.34)\n",
      "Brain data:\n",
      "R2 Scores: -21.4640 (+/- 43.60)\n",
      "RMSE Scores: 72.3808 (+/- 22.98)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"params = {\n",
    "\t'n_estimators': 1850,\n",
    "\t'learning_rate': 0.016,\n",
    "\t'max_depth': 11,\n",
    "\t'lambda': 0.9550839455019401,\n",
    "\t'alpha': 7.1136077576753936,\n",
    "\t'min_child_weight': 16,\n",
    "\t'gamma': 7,\n",
    "\t'colsample_bytree': 0.1,\n",
    "\t'colsample_bylevel': 1.0,\n",
    "\t'colsample_bynode': 1.0,\n",
    "\n",
    "\tR2 Scores: 0.5456 (+/- 0.20)\n",
    "\tRMSE Scores: 108.6056 (+/- 25.18)\n",
    "}\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Blood data:\n",
    "R2 Scores: 0.3749 (+/- 0.29)\n",
    "RMSE Scores: 4.1023 (+/- 1.46)\n",
    "Brain data:\n",
    "R2 Scores: 0.5248 (+/- 0.27)\n",
    "RMSE Scores: 56.1579 (+/- 29.28)\n",
    "\"\"\"\n",
    "if regressor_type != 'LGBM':\n",
    "\tblood_params = {\n",
    "\t\t'n_estimators': 1850,\n",
    "\t\t'learning_rate': 0.016,\n",
    "\t\t'max_depth': 30,\n",
    "\t\t'lambda': 0.21396204986950074,\n",
    "\t\t'alpha': 9.722159852062028,\n",
    "\t\t'min_child_weight': 9,\n",
    "\t\t'gamma': 0,\n",
    "\t\t'colsample_bytree': 0.8,\n",
    "\t\t'colsample_bylevel': 0.9,\n",
    "\t\t'colsample_bynode': 0.3,\n",
    "\t}\n",
    "\n",
    "\tbrain_params = {\n",
    "\t\t'n_estimators': 1400,\n",
    "\t\t'learning_rate': 0.03,\n",
    "\t\t'max_depth': 2,\n",
    "\t\t'lambda': 0.07718586294091904,\n",
    "\t\t'alpha': 2.5070868940026005,\n",
    "\t\t'min_child_weight': 6,\n",
    "\t\t'gamma': 1,\n",
    "\t\t'colsample_bytree': 0.1,\n",
    "\t\t'colsample_bylevel': 0.9,\n",
    "\t\t'colsample_bynode': 0.7,\n",
    "\t}\n",
    "else:\t# LightGBM\n",
    "\tblood_params = {\n",
    "\t\t'boosting_type': 'dart',\n",
    "\t\t'max_depth': 27,\n",
    "\t\t'learning_rate': 0.012,\n",
    "\t\t'n_estimators': 1950,\n",
    "\t\t'objective': 'regression',\n",
    "\t\t'min_child_samples': 7,\n",
    "\t\t'reg_lambda': 8.742591593419672,\n",
    "\t\t'reg_alpha': 0.03613741302435425,\n",
    "\t}\n",
    "\n",
    "\tbrain_params = {\n",
    "\t\t'boosting_type': 'gbdt',\n",
    "\t\t'max_depth': 16,\n",
    "\t\t'learning_rate': 0.025,\n",
    "\t\t'n_estimators': 2550,\n",
    "\t\t'objective': 'regression',\n",
    "\t\t'min_child_samples': 28,\n",
    "\t\t'reg_lambda': 0.08538775926146094,\n",
    "\t\t'reg_alpha': 0.07632249600835359,\n",
    "\t}\n",
    "\n",
    "if regressor_type != 'LGBM':\n",
    "\tblood_model = XGBRegressor(**blood_params)\n",
    "\tblood_r2_scores, blood_rmse_scores = train_model(blood_X, blood_y, blood_model)\n",
    "\n",
    "\tbrain_model = XGBRegressor(**brain_params)\n",
    "\tbrain_r2_scores, brain_rmse_scores = train_model(brain_X, brain_y, brain_model)\n",
    "else:\n",
    "\tcallbacks = [lgb.log_evaluation(period=0)]\n",
    "\tblood_model = lgb.sklearn.LGBMRegressor(**blood_params)\n",
    "\tblood_r2_scores, blood_rmse_scores = train_model(blood_X, blood_y, blood_model, callback=callbacks)\n",
    "\n",
    "\tbrain_model = lgb.sklearn.LGBMRegressor(**brain_params)\n",
    "\tbrain_r2_scores, brain_rmse_scores = train_model(brain_X, brain_y, brain_model, callback=callbacks)\n",
    "\n",
    "print(\"Blood data:\")\n",
    "print(\"R2 Scores: %0.4f (+/- %0.2f)\" %\n",
    "    (blood_r2_scores.mean(), blood_r2_scores.std()))\n",
    "print(\"RMSE Scores: %0.4f (+/- %0.2f)\" %\n",
    "    (blood_rmse_scores.mean(), blood_rmse_scores.std()))\n",
    "\n",
    "print(\"Brain data:\")\n",
    "print(\"R2 Scores: %0.4f (+/- %0.2f)\" %\n",
    "    (brain_r2_scores.mean(), brain_r2_scores.std()))\n",
    "print(\"RMSE Scores: %0.4f (+/- %0.2f)\" %\n",
    "    (brain_rmse_scores.mean(), brain_rmse_scores.std()))\n",
    "# cv_times = 5\n",
    "# cv = KFold(n_splits=cv_times, shuffle=True)\n",
    "\n",
    "# r2_scores = np.empty(cv_times)\n",
    "# rmse_scores = np.empty(cv_times)\n",
    "# for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "#     X_train, X_test = X[train_idx], X[test_idx]\n",
    "#     y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "#     model = XGBRegressor(**params)\n",
    "#     model.fit(X_train, y_train, eval_set=[\n",
    "#         (X_test, y_test)], early_stopping_rounds=100, verbose=False)\n",
    "#     preds = model.predict(X_test)\n",
    "\n",
    "#     r2 = r2_score(y_test, preds)\n",
    "#     r2_scores[idx] = r2\n",
    "\n",
    "#     rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "#     rmse_scores[idx] = rmse\n",
    "# # print(cv_scores)\n",
    "# print(\"R2 Scores: %0.4f (+/- %0.2f)\" %\n",
    "#       (r2_scores.mean(), r2_scores.std()))\n",
    "# print(\"RMSE Scores: %0.4f (+/- %0.2f)\" %\n",
    "#       (rmse_scores.mean(), rmse_scores.std()))\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # smaller, better\n",
    "# MSE = mean_squared_error(y_test, y_pred)\n",
    "# # MSLE = mean_squared_log_error(y_test, y_pred)\n",
    "# MAE = mean_absolute_error(y_test, y_pred)\n",
    "# Median = median_absolute_error(y_test, y_pred)\n",
    "# # closer to 1 means better\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# print(\"MSE: \", MSE)\n",
    "# print(\"RMSE: \", np.sqrt(MSE))\n",
    "# # print(\"MSLE: \", MSLE)\n",
    "# print(\"MAE: \", MAE)\n",
    "# print(\"Median: \", Median)\n",
    "# print(\"r2: \", r2)\n",
    "\n",
    "# ['accuracy', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'average_precision', 'balanced_accuracy', 'completeness_score', 'explained_variance', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'fowlkes_mallows_score', 'homogeneity_score', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted', 'max_error', 'mutual_info_score', 'neg_brier_score', 'neg_log_loss', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_gamma_deviance', 'neg_mean_poisson_deviance', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_median_absolute_error', 'neg_root_mean_squared_error', 'normalized_mutual_info_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'r2', 'rand_score', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'roc_auc', 'roc_auc_ovo', 'roc_auc_ovo_weighted', 'roc_auc_ovr', 'roc_auc_ovr_weighted', 'top_k_accuracy', 'v_measure_score']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BBB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e16bf243da0930d7340ce187bde8e3a4b0a6cf5e6333c4d640cd2c98ac77f14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
